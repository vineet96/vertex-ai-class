{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNtglf7PH2BHmJiQFsmxMOz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vineet96/vertex-ai-class/blob/main/Text_classification_VerteXAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QCIUWdngHSi_"
      },
      "outputs": [],
      "source": [
        "! pip3 install --upgrade --quiet google-cloud-aiplatform \\\n",
        "                                    google-cloud-storage \\\n",
        "                                    jsonlines"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Automatically restart kernel after installs so that your environment can access the new packages\n",
        "import IPython\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ],
      "metadata": {
        "id": "d9n7dYovHu_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_ID = \"vertexai-dev-387420\"  # @param {type:\"string\"}\n",
        "\n",
        "# set the project id\n",
        "! gcloud config set project $PROJECT_ID"
      ],
      "metadata": {
        "id": "776tg5DzH1Nb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "REGION = \"us-central1\"  # @param {type: \"string\"}"
      ],
      "metadata": {
        "id": "MS1nlruMH9G9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "IX_4E0ntIGuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BUCKET_NAME = \"vertexai-dev-text-classification\"  # @param {type:\"string\"}\n",
        "BUCKET_URI = f\"gs://{BUCKET_NAME}\"\n",
        "! gsutil mb -l $REGION $BUCKET_URI"
      ],
      "metadata": {
        "id": "5M4_OZC6IKwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import jsonlines\n",
        "from google.cloud import aiplatform, storage\n",
        "from google.cloud.aiplatform import jobs"
      ],
      "metadata": {
        "id": "GwRpwLWXIZQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aiplatform.init(project=PROJECT_ID, location=REGION)"
      ],
      "metadata": {
        "id": "0Bz6Z-TpIbrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a Dataset resource and import your data"
      ],
      "metadata": {
        "id": "C05wTggHIngV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Use a timestamp to ensure unique resources\n",
        "# src_uris = \"gs://vertexai-dev-text-classification/data_happiness.csv\"\n",
        "# display_name = \"text-classification-dataset\"\n",
        "\n",
        "# text_dataset = aiplatform.TextDataset.create(\n",
        "#     display_name=display_name,\n",
        "#     gcs_source=src_uris,\n",
        "#     import_schema_uri=aiplatform.schema.dataset.ioformat.text.single_label_classification,\n",
        "#     sync=True,\n",
        "# )"
      ],
      "metadata": {
        "id": "ZPEgJY6zIoqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Access Dataset resource with Dateset_id"
      ],
      "metadata": {
        "id": "_IyZWLRYJLlu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_dataset = aiplatform.TextDataset('6067806650486489088')"
      ],
      "metadata": {
        "id": "21BwTmAmJJdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a Training job"
      ],
      "metadata": {
        "id": "otsRzRbvJwIW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# training_job_display_name = \"text-classification-model\"\n",
        "# job = aiplatform.AutoMLTextTrainingJob(\n",
        "#     display_name=training_job_display_name,\n",
        "#     prediction_type=\"classification\",\n",
        "#     multi_label=False,\n",
        "# )"
      ],
      "metadata": {
        "id": "S_vgZ-HWJzKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run Training Job and Create the model"
      ],
      "metadata": {
        "id": "rw2x5g7UKFbC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model_display_name = \"text-classification-model\"\n",
        "\n",
        "# # Run the training job\n",
        "# model = job.run(\n",
        "#     dataset=text_dataset,\n",
        "#     model_display_name=model_display_name,\n",
        "#     training_fraction_split=0.8,\n",
        "#     validation_fraction_split=0.1,\n",
        "#     test_fraction_split=0.1,\n",
        "#     sync=True,\n",
        "# )"
      ],
      "metadata": {
        "id": "gH7q2533KVzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Access Model with model-id"
      ],
      "metadata": {
        "id": "bH7YOmh7Khli"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "fp6Tj3vdb1ec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = aiplatform.Model(\"projects/1052777806387/locations/us-central1/models/c12345678\")"
      ],
      "metadata": {
        "id": "agBalUiCKkdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deploy your model to an endpoint for online prediction"
      ],
      "metadata": {
        "id": "JCz7zg9uLt7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# deployed_model_display_name = \"text-classification-model\"\n",
        "\n",
        "# endpoint = model.deploy(\n",
        "#     deployed_model_display_name=deployed_model_display_name, sync=True\n",
        "# )"
      ],
      "metadata": {
        "id": "JM-vSeZnL1Ic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "endpoint = aiplatform.Endpoint('1026358920156807168')"
      ],
      "metadata": {
        "id": "ZA4iPQrxL-96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get Online prediction"
      ],
      "metadata": {
        "id": "u0FDVZP5b2RK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "content = \"I love my daughter\"\n",
        "\n",
        "response = endpoint.predict(instances=[{\"content\": content}])\n",
        "\n",
        "for prediction_ in response.predictions:\n",
        "    ids = prediction_[\"ids\"]\n",
        "    display_names = prediction_[\"displayNames\"]\n",
        "    confidence_scores = prediction_[\"confidences\"]\n",
        "    for count, id in enumerate(ids):\n",
        "        print(f\"Prediction ID: {id}\")\n",
        "        print(f\"Prediction display name: {display_names[count]}\")\n",
        "        print(f\"Prediction confidence score: {confidence_scores[count]}\")"
      ],
      "metadata": {
        "id": "QTofl2FDb4Us"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Batch Prediction"
      ],
      "metadata": {
        "id": "btM25kn8cu-9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instances = [\n",
        "    \"We hiked through the woods and up the hill to the ice caves\",\n",
        "    \"My kitten is so cute\",\n",
        "]\n",
        "input_file_name = \"batch-prediction-input.jsonl\""
      ],
      "metadata": {
        "id": "zV73o-hrcyeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the Storage client and create the new bucket\n",
        "# from google.cloud import  storage\n",
        "storage_client = storage.Client()\n",
        "bucket = storage_client.get_bucket(BUCKET_NAME)\n",
        "# Iterate over the prediction instances, creating a new TXT file\n",
        "# for each.\n",
        "input_file_data = []\n",
        "for count, instance in enumerate(instances):\n",
        "    instance_name = f\"input_{count}.txt\"\n",
        "    instance_file_uri = f\"{BUCKET_URI}/{instance_name}\"\n",
        "    # Add the data to store in the JSONL input file.\n",
        "    tmp_data = {\"content\": instance_file_uri, \"mimeType\": \"text/plain\"}\n",
        "    input_file_data.append(tmp_data)\n",
        "\n",
        "    # Create the new instance file\n",
        "    blob = bucket.blob(instance_name)\n",
        "    blob.upload_from_string(instance)\n",
        "\n",
        "input_str = \"\\n\".join([str(d) for d in input_file_data])\n",
        "file_blob = bucket.blob(f\"{input_file_name}\")\n",
        "\n",
        "file_blob.upload_from_string(input_str)"
      ],
      "metadata": {
        "id": "LMEJRMR6czXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job_display_name = \"e2e-text-classification-batch-prediction-job\"\n",
        "# model = aiplatform.Model(model_name=model.name)\n",
        "batch_prediction_job = model.batch_predict(\n",
        "    job_display_name=job_display_name,\n",
        "    gcs_source=\"gs://vertexai-dev-text-classification/batch-prediction-input.jsonl\",\n",
        "    gcs_destination_prefix=f\"{BUCKET_URI}/output\",\n",
        "    sync=True,\n",
        ")\n",
        "batch_prediction_job_name = batch_prediction_job.resource_name"
      ],
      "metadata": {
        "id": "_6AowO_NdGqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clean UP"
      ],
      "metadata": {
        "id": "7C6TsZYEdL9b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "delete_bucket = False\n",
        "\n",
        "if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
        "    ! gsutil rm -r $BUCKET_URI\n",
        "\n",
        "# Delete batch\n",
        "batch_job.delete()\n",
        "\n",
        "# Undeploy endpoint\n",
        "endpoint.undeploy_all()\n",
        "\n",
        "# `force` parameter ensures that models are undeployed before deletion\n",
        "endpoint.delete()\n",
        "\n",
        "# Delete model\n",
        "model.delete()\n",
        "\n",
        "# Delete text dataset\n",
        "text_dataset.delete()\n",
        "\n",
        "# Delete training job\n",
        "job.delete()"
      ],
      "metadata": {
        "id": "ezNfMS4udNQQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}